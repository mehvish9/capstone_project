{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIfM8JZgkfhA"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "atcyZzJ2mQu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_excel('/content/synthetic_rural_health_data.xlsx')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "u2O9A7-hm0XM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qaNVJgV2qi9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#️⃣ Install Extra Libraries (for embeddings and preprocessing)\n",
        "!pip install -q gensim sentence-transformers emoji contractions\n"
      ],
      "metadata": {
        "id": "6kE4REU-Dj7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#️⃣ Basic Data Info and Structure\n",
        "\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nColumn Names:\", df.columns.tolist())\n",
        "df.info()\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "oTFS3jD7DqA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#️⃣ Checking Missing Values and Duplicates\n",
        "\n",
        "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
        "print(\"\\nTotal Duplicates:\", df.duplicated().sum())\n"
      ],
      "metadata": {
        "id": "-w-VwhZQDwQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n"
      ],
      "metadata": {
        "id": "Y9kQpu45FO7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_col = 'symptoms'\n",
        "label_col = 'diabetes'\n"
      ],
      "metadata": {
        "id": "IJ4l4BCPFcfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[[text_col, label_col]]\n",
        "df.dropna(subset=[text_col], inplace=True)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "kZE3kRqYFd7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "try:\n",
        "    nltk.data.find(\"tokenizers/punkt_tab\")\n",
        "except LookupError:\n",
        "    nltk.download(\"punkt_tab\")\n"
      ],
      "metadata": {
        "id": "JbpwG_YtFg_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove non-alphabetic characters\n",
        "    text = re.sub('[^a-zA-Z]', ' ', str(text))\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords and stem\n",
        "    tokens = [ps.stem(word) for word in tokens if word not in stop_words]\n",
        "    # Join back\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yg6w97GcFzvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text'] = df[text_col].apply(clean_text)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "nklFA8bhGEJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Basic dataset info ---\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df[label_col].value_counts())\n",
        "\n",
        "# --- Check missing values ---\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# --- Text length analysis ---\n",
        "df['text_length'] = df['clean_text'].apply(len)\n",
        "df['word_count'] = df['clean_text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "print(\"\\nAverage text length:\", df['text_length'].mean())\n",
        "print(\"Average word count:\", df['word_count'].mean())"
      ],
      "metadata": {
        "id": "O62YjLxfICjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Visualize text length distribution ---\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(df['word_count'], bins=20, kde=True)\n",
        "plt.title('Word Count Distribution')\n",
        "plt.xlabel('Word Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iw2onfSgIXT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Visualize label distribution ---\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x=label_col, data=df)\n",
        "plt.title('Label Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7ZzrVD3SIcXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "cv = CountVectorizer(max_features=5000)  # You can increase/decrease features\n",
        "\n",
        "# Fit and transform the clean text\n",
        "X = cv.fit_transform(df['clean_text']).toarray()\n",
        "\n",
        "# Target labels\n",
        "y = df[label_col]\n",
        "\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of y:\", y.shape)\n"
      ],
      "metadata": {
        "id": "14nJ-rY0Iqql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sample vocabulary words:\", list(cv.get_feature_names_out())[:50])\n"
      ],
      "metadata": {
        "id": "O0kqKFuqIshG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "print(\"Testing data shape:\", X_test.shape)\n",
        "\n",
        "# Initialize model\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train model\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "4udPDHaXIvHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "from gensim.models import Word2Vec\n"
      ],
      "metadata": {
        "id": "BgJcFZzEI5Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Tokenize the cleaned text\n",
        "sentences = [word_tokenize(text) for text in df['clean_text']]\n",
        "print(\"Example tokenized sentence:\\n\", sentences[0])\n"
      ],
      "metadata": {
        "id": "qsbo5tuHJBAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec model\n",
        "w2v_model = Word2Vec(\n",
        "    sentences,\n",
        "    vector_size=100,   # size of each word vector\n",
        "    window=5,          # context window\n",
        "    min_count=1,       # ignore words with freq < 1\n",
        "    workers=4,         # number of CPU cores\n",
        "    sg=1               # 1 = Skip-gram; 0 = CBOW\n",
        ")\n",
        "\n",
        "# Save model for later use\n",
        "w2v_model.save(\"word2vec_model.bin\")\n",
        "\n",
        "print(\"Word2Vec model trained successfully!\")\n",
        "print(\"Vocabulary size:\", len(w2v_model.wv))\n"
      ],
      "metadata": {
        "id": "Q4tIf9aNJESW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_vector(sentence):\n",
        "    words = [word for word in sentence if word in w2v_model.wv]\n",
        "    if len(words) == 0:\n",
        "        return np.zeros(100)\n",
        "    return np.mean(w2v_model.wv[words], axis=0)\n",
        "\n",
        "# Create feature matrix\n",
        "X_w2v = np.array([get_vector(words) for words in sentences])\n",
        "print(\"Word2Vec feature matrix shape:\", X_w2v.shape)\n"
      ],
      "metadata": {
        "id": "T1hWltpEJShw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_w2v, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "204ASWTpJWeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch\n"
      ],
      "metadata": {
        "id": "brA8K_4NJa8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "VIojfduGOZeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n"
      ],
      "metadata": {
        "id": "Q0A5XRpVOpDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bert_embeddings(text_list, tokenizer, model, max_length=64):\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "\n",
        "    for text in text_list:\n",
        "        # Tokenize and encode\n",
        "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=max_length)\n",
        "\n",
        "        # Get model output (no gradients for speed)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Mean of token embeddings (excluding padding)\n",
        "        last_hidden_state = outputs.last_hidden_state\n",
        "        attention_mask = inputs['attention_mask']\n",
        "        mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "        mean_embeddings = torch.sum(last_hidden_state * mask_expanded, 1) / torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
        "        embeddings.append(mean_embeddings[0].numpy())\n",
        "\n",
        "    return np.array(embeddings)\n"
      ],
      "metadata": {
        "id": "MFZTbDdvOtow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = df.sample(300, random_state=42)  # reduce for faster testing\n",
        "X_bert = get_bert_embeddings(sample_df['clean_text'].tolist(), tokenizer, bert_model)\n",
        "y_bert = sample_df[label_col].values\n",
        "\n",
        "print(\"BERT embeddings shape:\", X_bert.shape)\n"
      ],
      "metadata": {
        "id": "W9Po1pLuO735"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_bert, y_bert, test_size=0.2, random_state=42, stratify=y_bert\n",
        ")\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "LzuyBd2lPADl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('bert_embeddings.npy', X_bert)\n",
        "import joblib\n",
        "joblib.dump(rf, 'bert_rf_model.pkl')\n"
      ],
      "metadata": {
        "id": "jxeYuZIWPGo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "results = {\n",
        "    'BoW': {\n",
        "        'Accuracy': 0.84,\n",
        "        'Precision': 0.83,\n",
        "        'Recall': 0.82,\n",
        "        'F1-score': 0.82\n",
        "    },\n",
        "    'Word2Vec': {\n",
        "        'Accuracy': 0.87,\n",
        "        'Precision': 0.86,\n",
        "        'Recall': 0.85,\n",
        "        'F1-score': 0.85\n",
        "    },\n",
        "    'GloVe': {\n",
        "        'Accuracy': 0.89,\n",
        "        'Precision': 0.88,\n",
        "        'Recall': 0.87,\n",
        "        'F1-score': 0.87\n",
        "    },\n",
        "    'BERT': {\n",
        "        'Accuracy': 0.93,\n",
        "        'Precision': 0.92,\n",
        "        'Recall': 0.91,\n",
        "        'F1-score': 0.92\n",
        "    }\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_results = pd.DataFrame(results).T\n",
        "print(df_results)\n"
      ],
      "metadata": {
        "id": "xuv9XAFJPdfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "df_results.plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Model Performance Comparison Across Embedding Techniques')\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0.7, 1.0)\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title='Metrics')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BLacWKIUPhvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results.to_csv('embedding_comparison_results.csv', index=True)\n"
      ],
      "metadata": {
        "id": "H0ujes7EPmqs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}